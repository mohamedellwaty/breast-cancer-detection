{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14028996,"sourceType":"datasetVersion","datasetId":8933504}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport os\nimport random\nimport shutil\nimport time\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom torchvision import datasets, transforms\n\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n\ndef remove_corrupted_images(dataset_root):\n    print(\"Checking for corrupted images...\")\n    removed = 0\n\n    if not os.path.exists(dataset_root):\n        raise FileNotFoundError(f\"Dataset root not found: {dataset_root}\")\n\n    for root, _, files in os.walk(dataset_root):\n        for f in files:\n            if not f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                continue\n            fp = os.path.join(root, f)\n            try:\n                Image.open(fp).verify()\n            except Exception:\n                try:\n                    os.remove(fp)\n                except:\n                    pass\n                removed += 1\n\n    print(f\"Removed corrupted images: {removed}\")\n\n\ndef split_dataset(source_dir, dest_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n    if os.path.exists(dest_dir):\n        # امسح القديم عشان مايتكرر نسخ\n        shutil.rmtree(dest_dir)\n\n    os.makedirs(dest_dir, exist_ok=True)\n\n    classes = [c for c in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, c))]\n    if not classes:\n        raise RuntimeError(\"No class folders found. لازم يكون عندك class0 و class1 جوه فولدر الداتا\")\n\n    for split_name in [\"train\", \"val\", \"test\"]:\n        for cls in classes:\n            os.makedirs(os.path.join(dest_dir, split_name, cls), exist_ok=True)\n\n    for cls in classes:\n        class_path = os.path.join(source_dir, cls)\n        images = [img for img in os.listdir(class_path) if img.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n        random.shuffle(images)\n\n        total = len(images)\n        if total == 0:\n            print(f\"Warning: class {cls} has 0 images\")\n            continue\n\n        train_end = int(train_ratio * total)\n        val_end = int((train_ratio + val_ratio) * total)\n\n        splits = {\n            \"train\": images[:train_end],\n            \"val\": images[train_end:val_end],\n            \"test\": images[val_end:]\n        }\n\n        for split_name, split_images in splits.items():\n            for img in split_images:\n                src = os.path.join(class_path, img)\n                dst = os.path.join(dest_dir, split_name, cls, img)\n                shutil.copy2(src, dst)\n\n    print(\"Dataset split completed\")\n\n\nIMG_SIZE = 50\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(30),\n    transforms.RandomGrayscale(p=0.25),\n    transforms.ColorJitter(brightness=0.35, contrast=0.35, saturation=0.25, hue=0.02),\n    transforms.RandomAutocontrast(p=0.25),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\neval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\n\ndef make_loaders(split_root, batch_size=128, num_workers=4, pin_memory=True):\n    train_dir = os.path.join(split_root, \"train\")\n    val_dir = os.path.join(split_root, \"val\")\n    test_dir = os.path.join(split_root, \"test\")\n\n    train_ds = datasets.ImageFolder(train_dir, transform=train_transform)\n    val_ds = datasets.ImageFolder(val_dir, transform=eval_transform)\n    test_ds = datasets.ImageFolder(test_dir, transform=eval_transform)\n\n    print(\"class_to_idx:\", train_ds.class_to_idx)\n\n    # Balance sampler عشان class0 عندك أكبر بكتير\n    targets = [y for _, y in train_ds.samples]\n    class_counts = torch.bincount(torch.tensor(targets))\n    class_weights = 1.0 / (class_counts.float() + 1e-6)\n    sample_weights = class_weights[torch.tensor(targets)]\n    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\n    train_loader = DataLoader(\n        train_ds, batch_size=batch_size, sampler=sampler,\n        num_workers=num_workers, pin_memory=pin_memory, persistent_workers=(num_workers > 0)\n    )\n    val_loader = DataLoader(\n        val_ds, batch_size=batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=pin_memory, persistent_workers=(num_workers > 0)\n    )\n    test_loader = DataLoader(\n        test_ds, batch_size=batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=pin_memory, persistent_workers=(num_workers > 0)\n    )\n\n    return train_loader, val_loader, test_loader, train_ds\n\n\nclass CNN_Manual_50(nn.Module):\n    def __init__(self, num_classes=2):\n        super().__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 50 -> 25\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 25 -> 12\n\n            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 12 -> 6\n\n            nn.Dropout(0.25),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256 * 6 * 6, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    for x, y in loader:\n        x = x.to(device, non_blocking=True)\n        y = y.to(device, non_blocking=True)\n\n        out = model(x)\n        loss = criterion(out, y)\n\n        loss_sum += loss.item()\n        pred = out.argmax(dim=1)\n        total += y.size(0)\n        correct += (pred == y).sum().item()\n\n    acc = 100.0 * correct / max(1, total)\n    avg_loss = loss_sum / max(1, len(loader))\n    return acc, avg_loss\n\n\ndef train(model, train_loader, val_loader, device, epochs=10, lr=1e-3, save_path=\"cnn_manual_50.pth\"):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    use_amp = (device.type == \"cuda\")\n    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n\n    best_val_acc = -1.0\n\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        model.train()\n\n        loss_sum = 0.0\n        correct = 0\n        total = 0\n\n        for x, y in train_loader:\n            x = x.to(device, non_blocking=True)\n            y = y.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast(\"cuda\", enabled=use_amp):\n                out = model(x)\n                loss = criterion(out, y)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            loss_sum += loss.item()\n            pred = out.argmax(dim=1)\n            total += y.size(0)\n            correct += (pred == y).sum().item()\n\n        train_acc = 100.0 * correct / max(1, total)\n        train_loss = loss_sum / max(1, len(train_loader))\n\n        val_acc, val_loss = evaluate(model, val_loader, criterion, device)\n        dt = time.time() - t0\n\n        print(f\"Epoch {ep}/{epochs} | Train Loss {train_loss:.4f} Acc {train_acc:.2f}% | Val Loss {val_loss:.4f} Acc {val_acc:.2f}% | Time {dt:.1f}s\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\n                \"model_state\": model.state_dict(),\n                \"class_to_idx\": getattr(train_loader.dataset, \"class_to_idx\", None),\n                \"img_size\": IMG_SIZE,\n                \"arch\": \"CNN_Manual_50\"\n            }, save_path)\n            print(f\"Model saved to {save_path}\")\n\n\ndef main():\n    set_seed(42)\n    torch.backends.cudnn.benchmark = True\n\n    RAW_PATH = \"/kaggle/input/imagefolder2/Dataset\"\n    SPLIT_PATH = \"/kaggle/working/cleaned_data\"\n    MODEL_PATH = r\"/kaggle/working/cnn_manual_50.pth\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Using device:\", device)\n    print(\"Torch version:\", torch.__version__)\n    print(\"CUDA available:\", torch.cuda.is_available())\n\n    remove_corrupted_images(RAW_PATH)\n    split_dataset(RAW_PATH, SPLIT_PATH)\n\n    train_loader, val_loader, test_loader, train_ds = make_loaders(\n        SPLIT_PATH, batch_size=128, num_workers=4, pin_memory=True\n    )\n\n    num_classes = len(train_ds.class_to_idx)\n    model = CNN_Manual_50(num_classes=num_classes).to(device)\n\n    train(model, train_loader, val_loader, device, epochs=10, lr=1e-3, save_path=MODEL_PATH)\n\n    test_acc, test_loss = evaluate(model, test_loader, nn.CrossEntropyLoss(), device)\n    print(f\"Test Accuracy: {test_acc:.2f}% | Test Loss: {test_loss:.4f}\")\n    print(\"Final model path:\", MODEL_PATH)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"id":"N4iwwPyV18BT","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:24:19.048158Z","iopub.execute_input":"2025-12-27T05:24:19.048721Z","iopub.status.idle":"2025-12-27T06:14:50.437959Z","shell.execute_reply.started":"2025-12-27T05:24:19.048693Z","shell.execute_reply":"2025-12-27T06:14:50.436853Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTorch version: 2.6.0+cu124\nCUDA available: True\nChecking for corrupted images...\nRemoved corrupted images: 0\nDataset split completed\nclass_to_idx: {'class0': 0, 'class1': 1}\nEpoch 1/10 | Train Loss 0.5097 Acc 78.02% | Val Loss 0.4349 Acc 80.40% | Time 123.1s\nModel saved to /kaggle/working/cnn_manual_50.pth\nEpoch 2/10 | Train Loss 0.4572 Acc 79.86% | Val Loss 0.4347 Acc 80.20% | Time 119.8s\nEpoch 3/10 | Train Loss 0.4439 Acc 80.74% | Val Loss 0.3450 Acc 85.60% | Time 119.9s\nModel saved to /kaggle/working/cnn_manual_50.pth\nEpoch 4/10 | Train Loss 0.4245 Acc 81.67% | Val Loss 0.4336 Acc 81.68% | Time 119.8s\nEpoch 5/10 | Train Loss 0.4118 Acc 82.31% | Val Loss 0.3483 Acc 85.47% | Time 118.5s\nEpoch 6/10 | Train Loss 0.3984 Acc 82.99% | Val Loss 0.4525 Acc 78.75% | Time 118.0s\nEpoch 7/10 | Train Loss 0.3938 Acc 83.33% | Val Loss 0.3511 Acc 83.92% | Time 117.5s\nEpoch 8/10 | Train Loss 0.3832 Acc 83.83% | Val Loss 0.3324 Acc 85.52% | Time 117.9s\nEpoch 9/10 | Train Loss 0.3749 Acc 84.24% | Val Loss 0.2732 Acc 87.98% | Time 118.4s\nModel saved to /kaggle/working/cnn_manual_50.pth\nEpoch 10/10 | Train Loss 0.3711 Acc 84.45% | Val Loss 0.2926 Acc 87.35% | Time 119.0s\nTest Accuracy: 87.45% | Test Loss: 0.2898\nFinal model path: /kaggle/working/cnn_manual_50.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import shutil\nimport os\n\ncleaned_dir = \"/kaggle/working/cleaned_data\"\n\nprint(\"Exists:\", os.path.exists(cleaned_dir))\nprint(\"Contents:\", os.listdir(cleaned_dir))\n\nshutil.make_archive(\n    \"/kaggle/working/cleaned_data\",  # output zip name\n    \"zip\",\n    cleaned_dir\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:15:51.128063Z","iopub.execute_input":"2025-12-27T06:15:51.128587Z","iopub.status.idle":"2025-12-27T06:16:43.939430Z","shell.execute_reply.started":"2025-12-27T06:15:51.128551Z","shell.execute_reply":"2025-12-27T06:16:43.938694Z"}},"outputs":[{"name":"stdout","text":"Exists: True\nContents: ['train', 'val', 'test']\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/cleaned_data.zip'"},"metadata":{}}],"execution_count":2}]}